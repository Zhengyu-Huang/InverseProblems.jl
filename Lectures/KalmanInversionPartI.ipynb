{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter on the Stationary Dynamics\n",
    "\n",
    "The inverse problem \n",
    "\n",
    "$$y = \\mathcal{G}(\\theta) + \\eta$$\n",
    "\n",
    "can be solved by first introducing a (mean-field) stochastic dynamical system in which the parameter-to-data map is embedded and then employing techniques from nonlinear Kalman filtering.\n",
    "\n",
    "Consider a family of stochastic dynamical systems\n",
    "\n",
    "$$\\begin{align}\n",
    "  &\\textrm{evolution:}    &&\\theta_{n+1} = r + \\alpha (\\theta_{n}  - r) +  \\omega_{n+1}, &&\\omega_{n+1} \\sim \\mathcal{N}(0,\\Sigma_{\\omega}),\\\\\n",
    "  &\\textrm{observation:}  &&x_{n+1} = \\mathcal{F}(\\theta_{n+1}) + \\nu_{n+1}, &&\\nu_{n+1} \\sim \\mathcal{N}(0,\\Sigma_{\\nu}).\n",
    "\\end{align}$$\n",
    "\n",
    "Then different Kalman filters can be employed on these stochastic dynamical systems, which leads to different Kalman inversion algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization approach [1]\n",
    "\n",
    "This approach aims to finding the *best* $\\theta$ for ill-posed inverse problems, where an effective regularization is incorporated.\n",
    "\n",
    "\n",
    "Consider the case :\n",
    "* $\\alpha \\in [0, 1]$, $r = r_0$ is the prior mean, $\\Sigma_{\\omega} = \\gamma \\Sigma_{0}$, where  $\\Sigma_{0}$ is the prior covariance.  \n",
    "* $x_{n+1} = y$, $\\mathcal{F} = \\mathcal{G}$, and $\\Sigma_{\\nu} = \\frac{\\gamma}{\\gamma - 1} \\Sigma_{\\eta}$\n",
    "\n",
    "where the hyperparameter $\\gamma > 1$ is set to be $2$. When $\\alpha = 1$ the evolution model is an identical map; when $\\alpha \\in [0, 1)$, the model has a stationery point $r$, and therefore regularization toward $r$ is added:\n",
    "* When the observation noise is negligible, and there are more observations than parameters (identifiable inverse problem) $\\alpha = 1$ (no regularization)\n",
    "* Otherwise $\\alpha < 1$. The smaller $\\alpha$ is, the closer Kalman inversion will converge to the prior mean.\n",
    "    \n",
    "    \n",
    "\n",
    "## Linear Analysis\n",
    "In the linear setting, $\\mathcal{G}(\\theta) = G\\cdot \\theta$\n",
    "The update equations become\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\hat{m}_{n+1} &= \\alpha m_n + (1-\\alpha)r_0,\\\\\n",
    "    \\hat{C}_{n+1} &=  \\alpha^2 C_{n} + \\Sigma_{\\omega},\n",
    "\\end{align*}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\begin{align*}\n",
    "        m_{n+1} &= \\hat{m}_{n+1} + \\hat{C}_{n+1} G^T (G  \\hat{C}_{n+1} G^T + \\Sigma_{\\nu})^{-1} \\Big(y - G\\hat{m}_{n+1} \\Big), \\\\\n",
    "        C_{n+1}&= \\hat{C}_{n+1} - \\hat{C}_{n+1} G^T(G  \\hat{C}_{n+1} G^T + \\Sigma_{\\nu})^{-1} G \\hat{C}_{n+1}. \\end{align*}\n",
    "$$\n",
    "\n",
    "We have the following theorem about the convergence of the \n",
    "algorithm in the setting of the linear forward model:\n",
    "\n",
    "**Theorem**\n",
    "Assume that $\\Sigma_{\\omega}\\succ 0$ and $\\Sigma_{\\nu}\\succ 0.$ Consider the iteration mapping\n",
    "$(m_n,C_n)$ into $(m_{n+1},C_{n+1})$. Assume further \n",
    "that $\\alpha \\in (0,1)$ or that\n",
    "$\\alpha=1$ and\n",
    "$\\text{Range}(G^T)=\\mathbb{R}^{N_{\\theta}}$.\n",
    "Then the steady state equation of the covariance\n",
    "\n",
    "$$\n",
    "C_{\\infty}^{-1} =  G^T\\Sigma_{\\nu}^{-1}G + (\\alpha^2 C_{\\infty} + \\Sigma_{\\omega})^{-1}\n",
    "$$\n",
    "\n",
    "has a unique solution $C_{\\infty} \\succ 0.$ \n",
    "The pair $(m_n,C_n)$\n",
    "converges exponentially fast to  limit $(m_{\\infty},C_{\\infty})$.\n",
    "Furthermore the limiting mean $m_{\\infty}$ is the minimizer\n",
    "of the Tikhonov regularized least squares\n",
    "functional $\\Phi_R$ given by\n",
    "\n",
    "$$\n",
    "\\Phi_R(\\theta) := \\frac{1}{2}\\lVert\\Sigma_{\\nu}^{-\\frac{1}{2}}(y - G\\theta) \\rVert^2 +\n",
    "\\frac{1 - \\alpha}{2}\\lVert \\hat{C}_{\\infty}^{-\\frac{1}{2}}(\\theta - r_0) \\rVert^2,\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\hat{C}_{\\infty} =\\alpha^2 C_{\\infty} + \\Sigma_{\\omega}.\n",
    "$$\n",
    "\n",
    "**Remark**\n",
    "Despite the clear parallels between $\\Phi_R$ and Tikhonov regularization, there is an important\n",
    "difference: the matrix $\\hat{C}_{\\infty}$ defining the implied\n",
    "prior covariance in the regularization term\n",
    "depends on the forward model. \n",
    "To get some insight into the implications of this, we consider the over-determined linear system in which $G^T\\Sigma_{\\eta}^{-1}G$ is invertible\n",
    "and we may define\n",
    "$$\n",
    "{C_{*}} = (G^T\\Sigma_{\\eta}^{-1}G)^{-1}.\n",
    "$$\n",
    "If we choose the artificial evolution and observation error covariances\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Sigma_\\nu &= \\gamma \\Sigma_{\\eta},\\\\\n",
    "\\Sigma_{\\omega} &= \\bigl(\\frac{\\gamma}{\\gamma-1} - \\alpha^{2}\\bigl) C_{*},\n",
    "\\end{align*}\n",
    "$$\n",
    "then straightforward calculation shows that\n",
    "$$C_{\\infty}=C_{*}, \\quad \\hat{C}_{\\infty}=\\frac{\\gamma}{\\gamma-1}C_{*}.$$\n",
    "It follows that\n",
    "\n",
    "$$\n",
    "    \\Phi_R(\\theta)= \n",
    "     \\frac{1}{2\\gamma} \\left\\lVert \\Sigma_{\\eta}^{-\\frac{1}{2}}(y-G\\theta) \\right\\rVert^2 +\n",
    "    \\frac{(1-\\alpha)(\\gamma-1)}{2 \\gamma} \\left\\lVert \\Sigma_{\\eta}^{-\\frac{1}{2}}(Gr_0 - G \\theta) \\right\\rVert^2.\n",
    "$$\n",
    "\n",
    "This calculation clearly demonstrates the dependence of the second (regularization) term on the forward model and that choosing\n",
    "$\\alpha \\in (0,1]$ allows different weights on the regularization term.\n",
    "In contrast to Tikhonov regularization, the regularization term scales similarly with respect to $G$\n",
    "as does the data misfit, providing a regularization between \n",
    "the prior mean $r_0$ and an overfitted parameter  $\\theta^* : y = G\\theta^{*}$. Therefore, despite the differences from\n",
    "standard Tikhonov regularization, the implied regularization\n",
    "resulting from the proposed stochastic dynamical system\n",
    "is both interpretable and controllable; in particular, the\n",
    "single parameter $\\alpha$ measures the balance between prior\n",
    "and the overfitted solution.\n",
    "\n",
    "\n",
    "1. [Iterated Kalman Methodology For Inverse Problems](https://arxiv.org/abs/2102.01580)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic approach [2]\n",
    "\n",
    "This approach aims to finding the *best* Gaussian approximation of the posterior distribution of $\\theta$ for ill-posed inverse problems, where the prior is a Gaussian $\\mathcal{N}(r_0, \\Sigma_0)$.\n",
    "\n",
    "\n",
    "Consider the case :\n",
    "* $\\alpha = 1$,  $\\Sigma_{\\omega} = \\gamma C_{n}$, where  $C_{n}$ is the covariance estimation at the current step.  \n",
    "* $x_{n+1} = \\begin{bmatrix} y \\\\ r_0 \\end{bmatrix}, \\quad \n",
    "\\mathcal{F}(\\theta) = \\begin{bmatrix} \\mathcal{G}(\\theta) \\\\ \\theta  \\end{bmatrix},\\quad \n",
    "\\textrm{and}\\quad \\Sigma_{\\nu} = \\frac{\\gamma + 1}{\\gamma} \\begin{bmatrix} \\Sigma_{\\eta} & 0 \\\\ 0 & \\Sigma_0\\end{bmatrix}\n",
    "$ \n",
    "\n",
    "where $r_0$ and $\\Sigma_0$ are prior mean and covariance, and the hyperparameter $\\gamma > 0$ is set to be $1$. \n",
    "\n",
    "## Linear Analysis\n",
    "In the linear setting, \n",
    "\n",
    "$$\\mathcal{G}(\\theta) = G\\cdot \\theta \\qquad F = \\begin{bmatrix} G \\\\ I  \\end{bmatrix}$$\n",
    "\n",
    "The update equations become\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\hat{m}_{n+1} &=  m_n\\\\\n",
    "    \\hat{C}_{n+1} &=  (\\gamma + 1) C_{n}\n",
    "\\end{align*}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\begin{align*}\n",
    "        m_{n+1} &= m_{n+1} + \\hat{C}_{n+1} F^T (F  \\hat{C}_{n+1} F^T + \\Sigma_{\\nu,n+1})^{-1} (x_{n+1} - F m_{n}) \\\\\n",
    "         C_{n+1}&= \\hat{C}_{n+1} - \\hat{C}_{n+1} F^T(F  \\hat{C}_{n+1} F^T + \\Sigma_{\\nu,n+1})^{-1} F \\hat{C}_{n+1}, \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We have the following theorem about the convergence of the \n",
    "algorithm in the setting of the linear forward model:\n",
    "\n",
    "**Theorem**\n",
    "Assume that the prior covariance matrix $\\Sigma_{0} \\succ 0$ and initial covariance matrix $C_{0} \\succ 0.$\n",
    "%\n",
    "The iteration for the conditional mean $m_n$ and covariance matrix $C_{n}$ characterizing the distribution of $\\theta_n|Y_n$\n",
    "converges exponentially fast to posterior mean $m_{\\rm post}$ and covariance $C_{\\rm post}.$\n",
    "            \n",
    "            \n",
    "            \n",
    "2. [Efficient Derivative-free Bayesian Inference for Large-Scale Inverse Problems](https://arxiv.org/abs/2204.04386)\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic approach [3]\n",
    "\n",
    "This approach aims to finding the *best* Gaussian approximation of the posterior distribution of $\\theta$ for well-posed inverse problems (number of observations is larger than number of unknowns), where the prior is an improper uniform distribution in the whole space.\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "Consider the case :\n",
    "* $\\alpha = 1$,  $\\Sigma_{\\omega} = \\gamma C_{n}$, where  $C_{n}$ is the covariance estimation at the current step.  \n",
    "* $x_{n+1} = y, \\quad \n",
    "\\mathcal{F}(\\theta) =  \\mathcal{G}(\\theta),\\quad \\textrm{and}\\quad \n",
    "\\Sigma_{\\nu} = \\frac{\\gamma + 1}{\\gamma} \\Sigma_{\\eta}\n",
    "$ \n",
    "\n",
    "where the hyperparameter $\\gamma > 0$ is set to be $1$. \n",
    "\n",
    "## Linear Analysis\n",
    "In the linear setting, \n",
    "\n",
    "$$\\mathcal{G}(\\theta) = G\\cdot \\theta \\qquad F = G $$\n",
    "\n",
    "The update equations become\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\hat{m}_{n+1} &=  m_n\\\\\n",
    "    \\hat{C}_{n+1} &=  (\\gamma + 1) C_{n}\n",
    "\\end{align*}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\begin{align*}\n",
    "        m_{n+1} &= m_{n+1} + \\hat{C}_{n+1} G^T (G  \\hat{C}_{n+1} G^T + \\Sigma_{\\nu,n+1})^{-1} (x_{n+1} - G m_{n}) \\\\\n",
    "         C_{n+1}&= \\hat{C}_{n+1} - \\hat{C}_{n+1} G^T(G  \\hat{C}_{n+1} G^T + \\Sigma_{\\nu,n+1})^{-1} G \\hat{C}_{n+1}, \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We have the following theorem about the convergence of the \n",
    "algorithm in the setting of the linear forward model:\n",
    "\n",
    "**Theorem**\n",
    "Assume the inverse problem is well-defined, namely $\\text{Range}(G^T)=\\mathbb{R}^{N_{\\theta}}$, and the initial covariance matrix $C_{0} \\succ 0$ is strictly positive definite. \n",
    "\n",
    "* The iteration for the conditional mean $m_n$ and covariance matrix $C_{n}$ characterizing the distribution of $\\theta_n|Y_n$\n",
    "converges exponentially fast to posterior mean and covariance with an improper uniform prior \n",
    "\n",
    "$$\n",
    "m_{\\rm post} = argmin \\frac{1}{2}\\lVert \\Sigma_{\\eta}^{-1}\\Bigl(y - G\\theta \\Bigr) \\rVert^2\\quad \\textrm{and} \\quad  C_{\\rm post} = \\Bigl(G^T \\Sigma_{\\eta}^{-1} G\\Bigr)^{-1}\n",
    "$$\n",
    "\n",
    "* The uncertainty is given as an error bound about the parameter estimation\n",
    "\n",
    "$$\n",
    "    P\\Big( |{\\theta_{ref}}_{(i)} - {m_{\\rm post}}_{(i)}| \\leq 3\\sqrt{{C_{\\rm post}}_{(i,i)}} \\Big) \\geq 99.7\\%,\n",
    "$$\n",
    "\n",
    "here the subscript $i$ represents the vector or matrix index, and $\\theta_{ref}$ represents the reference parameter, which satisfies $y - G\\theta_{ref} \\sim \\mathcal{N}(0, \\Sigma_{\\eta})$.          \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "3. [Bayesian Calibration for Large‚ÄêScale Fluid Structure Interaction Problems Under Embedded/Immersed Boundary Framework](https://arxiv.org/pdf/2105.09497.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
